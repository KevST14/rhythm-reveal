{"version":3,"sources":["../../../../src/client/components/segment-cache/cache.ts"],"sourcesContent":["import type {\n  TreePrefetch,\n  RootTreePrefetch,\n  SegmentPrefetch,\n} from '../../../server/app-render/collect-segment-data'\nimport type { LoadingModuleData } from '../../../shared/lib/app-router-context.shared-runtime'\nimport {\n  NEXT_ROUTER_PREFETCH_HEADER,\n  NEXT_ROUTER_SEGMENT_PREFETCH_HEADER,\n  NEXT_URL,\n  RSC_CONTENT_TYPE_HEADER,\n  RSC_HEADER,\n} from '../app-router-headers'\nimport {\n  createFetch,\n  createFromNextReadableStream,\n  urlToUrlWithoutFlightMarker,\n  type RequestHeaders,\n} from '../router-reducer/fetch-server-response'\nimport {\n  trackPrefetchRequestBandwidth,\n  pingPrefetchTask,\n  type PrefetchTask,\n  spawnPrefetchSubtask,\n} from './scheduler'\nimport { getAppBuildId } from '../../app-build-id'\nimport { createHrefFromUrl } from '../router-reducer/create-href-from-url'\nimport type {\n  NormalizedHref,\n  NormalizedNextUrl,\n  RouteCacheKey,\n} from './cache-key'\nimport { createTupleMap, type TupleMap, type Prefix } from './tuple-map'\nimport { createLRU, type LRU } from './lru'\n\n// A note on async/await when working in the prefetch cache:\n//\n// Most async operations in the prefetch cache should *not* use async/await,\n// Instead, spawn a subtask that writes the results to a cache entry, and attach\n// a \"ping\" listener to notify the prefetch queue to try again.\n//\n// The reason is we need to be able to access the segment cache and traverse its\n// data structures synchronously. For example, if there's a synchronous update\n// we can take an immediate snapshot of the cache to produce something we can\n// render. Limiting the use of async/await also makes it easier to avoid race\n// conditions, which is especially important because is cache is mutable.\n//\n// Another reason is that while we're performing async work, it's possible for\n// existing entries to become stale, or for Link prefetches to be removed from\n// the queue. For optimal scheduling, we need to be able to \"cancel\" subtasks\n// that are no longer needed. So, when a segment is received from the server, we\n// restart from the root of the tree that's being prefetched, to confirm all the\n// parent segments are still cached. If the segment is no longer reachable from\n// the root, then it's effectively canceled. This is similar to the design of\n// Rust Futures, or React Suspense.\n\ntype RouteCacheEntryShared = {\n  staleAt: number\n  // This is false only if we're certain the route cannot be intercepted. It's\n  // true in all other cases, including on initialization when we haven't yet\n  // received a response from the server.\n  couldBeIntercepted: boolean\n\n  // LRU-related fields\n  keypath: null | Prefix<RouteCacheKeypath>\n  next: null | RouteCacheEntry\n  prev: null | RouteCacheEntry\n  size: number\n}\n\nexport const enum EntryStatus {\n  Pending,\n  Rejected,\n  Fulfilled,\n}\n\ntype PendingRouteCacheEntry = RouteCacheEntryShared & {\n  status: EntryStatus.Pending\n  blockedTasks: Set<PrefetchTask> | null\n  canonicalUrl: null\n  tree: null\n  head: null\n  isHeadPartial: true\n}\n\ntype RejectedRouteCacheEntry = RouteCacheEntryShared & {\n  status: EntryStatus.Rejected\n  blockedTasks: Set<PrefetchTask> | null\n  canonicalUrl: null\n  tree: null\n  head: null\n  isHeadPartial: true\n}\n\nexport type FulfilledRouteCacheEntry = RouteCacheEntryShared & {\n  status: EntryStatus.Fulfilled\n  blockedTasks: null\n  canonicalUrl: string\n  tree: TreePrefetch\n  head: React.ReactNode | null\n  isHeadPartial: boolean\n}\n\nexport type RouteCacheEntry =\n  | PendingRouteCacheEntry\n  | FulfilledRouteCacheEntry\n  | RejectedRouteCacheEntry\n\ntype SegmentCacheEntryShared = {\n  staleAt: number\n\n  // LRU-related fields\n  key: null | string\n  next: null | RouteCacheEntry\n  prev: null | RouteCacheEntry\n  size: number\n}\n\ntype PendingSegmentCacheEntry = SegmentCacheEntryShared & {\n  status: EntryStatus.Pending\n  rsc: null\n  loading: null\n  isPartial: true\n  promise: null | PromiseWithResolvers<FulfilledSegmentCacheEntry | null>\n}\n\ntype RejectedSegmentCacheEntry = SegmentCacheEntryShared & {\n  status: EntryStatus.Rejected\n  rsc: null\n  loading: null\n  isPartial: true\n  promise: null\n}\n\ntype FulfilledSegmentCacheEntry = SegmentCacheEntryShared & {\n  status: EntryStatus.Fulfilled\n  rsc: React.ReactNode | null\n  loading: LoadingModuleData | Promise<LoadingModuleData>\n  isPartial: boolean\n  promise: null\n}\n\nexport type SegmentCacheEntry =\n  | PendingSegmentCacheEntry\n  | RejectedSegmentCacheEntry\n  | FulfilledSegmentCacheEntry\n\n// Route cache entries vary on multiple keys: the href and the Next-Url. Each of\n// these parts needs to be included in the internal cache key. Rather than\n// concatenate the keys into a single key, we use a multi-level map, where the\n// first level is keyed by href, the second level is keyed by Next-Url, and so\n// on (if were to add more levels).\ntype RouteCacheKeypath = [NormalizedHref, NormalizedNextUrl]\nconst routeCacheMap: TupleMap<RouteCacheKeypath, RouteCacheEntry> =\n  createTupleMap()\n\n// We use an LRU for memory management. We must update this whenever we add or\n// remove a new cache entry, or when an entry changes size.\n// TODO: I chose the max size somewhat arbitrarily. Consider setting this based\n// on navigator.deviceMemory, or some other heuristic. We should make this\n// customizable via the Next.js config, too.\nconst maxRouteLruSize = 10 * 1024 * 1024 // 10 MB\nconst routeCacheLru = createLRU<RouteCacheEntry>(\n  maxRouteLruSize,\n  onRouteLRUEviction\n)\n\n// TODO: We may eventually store segment entries in a tuple map, too, to\n// account for search params.\nconst segmentCacheMap = new Map<string, SegmentCacheEntry>()\n// NOTE: Segments and Route entries are managed by separate LRUs. We could\n// combine them into a single LRU, but because they are separate types, we'd\n// need to wrap each one in an extra LRU node (to maintain monomorphism, at the\n// cost of additional memory).\nconst maxSegmentLruSize = 50 * 1024 * 1024 // 50 MB\nconst segmentCacheLru = createLRU<SegmentCacheEntry>(\n  maxSegmentLruSize,\n  onSegmentLRUEviction\n)\n\nexport function readExactRouteCacheEntry(\n  now: number,\n  href: NormalizedHref,\n  nextUrl: NormalizedNextUrl | null\n): RouteCacheEntry | null {\n  const keypath: Prefix<RouteCacheKeypath> =\n    nextUrl === null ? [href] : [href, nextUrl]\n  const existingEntry = routeCacheMap.get(keypath)\n  if (existingEntry !== null) {\n    // Check if the entry is stale\n    if (existingEntry.staleAt > now) {\n      // Reuse the existing entry.\n\n      // Since this is an access, move the entry to the front of the LRU.\n      routeCacheLru.put(existingEntry)\n\n      return existingEntry\n    } else {\n      // Evict the stale entry from the cache.\n      deleteRouteFromCache(existingEntry, keypath)\n    }\n  }\n  return null\n}\n\nexport function readRouteCacheEntry(\n  now: number,\n  key: RouteCacheKey\n): RouteCacheEntry | null {\n  // First check if there's a non-intercepted entry. Most routes cannot be\n  // intercepted, so this is the common case.\n  const nonInterceptedEntry = readExactRouteCacheEntry(now, key.href, null)\n  if (nonInterceptedEntry !== null && !nonInterceptedEntry.couldBeIntercepted) {\n    // Found a match, and the route cannot be intercepted. We can reuse it.\n    return nonInterceptedEntry\n  }\n  // There was no match. Check again but include the Next-Url this time.\n  return readExactRouteCacheEntry(now, key.href, key.nextUrl)\n}\n\nexport function readSegmentCacheEntry(\n  now: number,\n  path: string\n): SegmentCacheEntry | null {\n  const existingEntry = segmentCacheMap.get(path)\n  if (existingEntry !== undefined) {\n    // Check if the entry is stale\n    if (existingEntry.staleAt > now) {\n      // Reuse the existing entry.\n\n      // Since this is an access, move the entry to the front of the LRU.\n      segmentCacheLru.put(existingEntry)\n\n      return existingEntry\n    } else {\n      // Evict the stale entry from the cache.\n      deleteSegmentFromCache(existingEntry, path)\n    }\n  }\n  return null\n}\n\nexport function waitForSegmentCacheEntry(\n  pendingEntry: PendingSegmentCacheEntry\n): Promise<FulfilledSegmentCacheEntry | null> {\n  // Because the entry is pending, there's already a in-progress request.\n  // Attach a promise to the entry that will resolve when the server responds.\n  let promiseWithResolvers = pendingEntry.promise\n  if (promiseWithResolvers === null) {\n    promiseWithResolvers = pendingEntry.promise =\n      createPromiseWithResolvers<FulfilledSegmentCacheEntry | null>()\n  } else {\n    // There's already a promise we can use\n  }\n  return promiseWithResolvers.promise\n}\n\n/**\n * Reads the route cache for a matching entry *and* spawns a request if there's\n * no match. Because this may issue a network request, it should only be called\n * from within the context of a prefetch task.\n */\nexport function requestRouteCacheEntryFromCache(\n  now: number,\n  task: PrefetchTask\n): RouteCacheEntry {\n  const key = task.key\n  // First check if there's a non-intercepted entry. Most routes cannot be\n  // intercepted, so this is the common case.\n  const nonInterceptedEntry = readExactRouteCacheEntry(now, key.href, null)\n  if (nonInterceptedEntry !== null && !nonInterceptedEntry.couldBeIntercepted) {\n    // Found a match, and the route cannot be intercepted. We can reuse it.\n    return nonInterceptedEntry\n  }\n  // There was no match. Check again but include the Next-Url this time.\n  const exactEntry = readExactRouteCacheEntry(now, key.href, key.nextUrl)\n  if (exactEntry !== null) {\n    return exactEntry\n  }\n  // Create a pending entry and spawn a request for its data.\n  const pendingEntry: PendingRouteCacheEntry = {\n    canonicalUrl: null,\n    status: EntryStatus.Pending,\n    blockedTasks: null,\n    tree: null,\n    head: null,\n    isHeadPartial: true,\n    // If the request takes longer than a minute, a subsequent request should\n    // retry instead of waiting for this one.\n    //\n    // When the response is received, this value will be replaced by a new value\n    // based on the stale time sent from the server.\n    staleAt: now + 60 * 1000,\n    // This is initialized to true because we don't know yet whether the route\n    // could be intercepted. It's only set to false once we receive a response\n    // from the server.\n    couldBeIntercepted: true,\n\n    // LRU-related fields\n    keypath: null,\n    next: null,\n    prev: null,\n    size: 0,\n  }\n  spawnPrefetchSubtask(fetchRouteOnCacheMiss(pendingEntry, task))\n  const keypath: Prefix<RouteCacheKeypath> =\n    key.nextUrl === null ? [key.href] : [key.href, key.nextUrl]\n  routeCacheMap.set(keypath, pendingEntry)\n  // Stash the keypath on the entry so we know how to remove it from the map\n  // if it gets evicted from the LRU.\n  pendingEntry.keypath = keypath\n  routeCacheLru.put(pendingEntry)\n  return pendingEntry\n}\n\n/**\n * Reads the route cache for a matching entry *and* spawns a request if there's\n * no match. Because this may issue a network request, it should only be called\n * from within the context of a prefetch task.\n */\nexport function requestSegmentEntryFromCache(\n  now: number,\n  task: PrefetchTask,\n  route: FulfilledRouteCacheEntry,\n  path: string,\n  accessToken: string\n): SegmentCacheEntry {\n  const existingEntry = readSegmentCacheEntry(now, path)\n  if (existingEntry !== null) {\n    return existingEntry\n  }\n  // Create a pending entry and spawn a request for its data.\n  const pendingEntry: PendingSegmentCacheEntry = {\n    status: EntryStatus.Pending,\n    rsc: null,\n    loading: null,\n    staleAt: route.staleAt,\n    isPartial: true,\n    promise: null,\n\n    // LRU-related fields\n    key: null,\n    next: null,\n    prev: null,\n    size: 0,\n  }\n  spawnPrefetchSubtask(\n    fetchSegmentEntryOnCacheMiss(\n      route,\n      pendingEntry,\n      task.key,\n      path,\n      accessToken\n    )\n  )\n  segmentCacheMap.set(path, pendingEntry)\n  // Stash the keypath on the entry so we know how to remove it from the map\n  // if it gets evicted from the LRU.\n  pendingEntry.key = path\n  segmentCacheLru.put(pendingEntry)\n  return pendingEntry\n}\n\nfunction deleteRouteFromCache(\n  entry: RouteCacheEntry,\n  keypath: Prefix<RouteCacheKeypath>\n): void {\n  pingBlockedTasks(entry)\n  routeCacheMap.delete(keypath)\n  routeCacheLru.delete(entry)\n}\n\nfunction deleteSegmentFromCache(entry: SegmentCacheEntry, key: string): void {\n  cancelEntryListeners(entry)\n  segmentCacheMap.delete(key)\n  segmentCacheLru.delete(entry)\n}\n\nfunction onRouteLRUEviction(entry: RouteCacheEntry): void {\n  // The LRU evicted this entry. Remove it from the map.\n  const keypath = entry.keypath\n  if (keypath !== null) {\n    entry.keypath = null\n    pingBlockedTasks(entry)\n    routeCacheMap.delete(keypath)\n  }\n}\n\nfunction onSegmentLRUEviction(entry: SegmentCacheEntry): void {\n  // The LRU evicted this entry. Remove it from the map.\n  const key = entry.key\n  if (key !== null) {\n    entry.key = null\n    cancelEntryListeners(entry)\n    segmentCacheMap.delete(key)\n  }\n}\n\nfunction cancelEntryListeners(entry: SegmentCacheEntry): void {\n  if (entry.status === EntryStatus.Pending && entry.promise !== null) {\n    // There were listeners for this entry. Resolve them with `null` to indicate\n    // that the prefetch failed. It's up to the listener to decide how to handle\n    // this case.\n    // NOTE: We don't currently propagate the reason the prefetch was canceled\n    // but we could by accepting a `reason` argument.\n    entry.promise.resolve(null)\n    entry.promise = null\n  }\n}\n\nfunction pingBlockedTasks(entry: {\n  blockedTasks: Set<PrefetchTask> | null\n}): void {\n  const blockedTasks = entry.blockedTasks\n  if (blockedTasks !== null) {\n    for (const task of blockedTasks) {\n      pingPrefetchTask(task)\n    }\n    entry.blockedTasks = null\n  }\n}\n\nfunction fulfillRouteCacheEntry(\n  entry: PendingRouteCacheEntry,\n  tree: TreePrefetch,\n  head: React.ReactNode,\n  isHeadPartial: boolean,\n  staleAt: number,\n  couldBeIntercepted: boolean,\n  canonicalUrl: string\n): FulfilledRouteCacheEntry {\n  const fulfilledEntry: FulfilledRouteCacheEntry = entry as any\n  fulfilledEntry.status = EntryStatus.Fulfilled\n  fulfilledEntry.tree = tree\n  fulfilledEntry.head = head\n  fulfilledEntry.isHeadPartial = isHeadPartial\n  fulfilledEntry.staleAt = staleAt\n  fulfilledEntry.couldBeIntercepted = couldBeIntercepted\n  fulfilledEntry.canonicalUrl = canonicalUrl\n  pingBlockedTasks(entry)\n  return fulfilledEntry\n}\n\nfunction fulfillSegmentCacheEntry(\n  segmentCacheEntry: PendingSegmentCacheEntry,\n  rsc: React.ReactNode,\n  loading: LoadingModuleData | Promise<LoadingModuleData>,\n  staleAt: number,\n  isPartial: boolean\n) {\n  const fulfilledEntry: FulfilledSegmentCacheEntry = segmentCacheEntry as any\n  fulfilledEntry.status = EntryStatus.Fulfilled\n  fulfilledEntry.rsc = rsc\n  fulfilledEntry.loading = loading\n  fulfilledEntry.staleAt = staleAt\n  fulfilledEntry.isPartial = isPartial\n  // Resolve any listeners that were waiting for this data.\n  if (segmentCacheEntry.promise !== null) {\n    segmentCacheEntry.promise.resolve(fulfilledEntry)\n    // Free the promise for garbage collection.\n    fulfilledEntry.promise = null\n  }\n}\n\nfunction rejectRouteCacheEntry(\n  entry: PendingRouteCacheEntry,\n  staleAt: number\n): void {\n  const rejectedEntry: RejectedRouteCacheEntry = entry as any\n  rejectedEntry.status = EntryStatus.Rejected\n  rejectedEntry.staleAt = staleAt\n  pingBlockedTasks(entry)\n}\n\nfunction rejectSegmentCacheEntry(\n  entry: PendingSegmentCacheEntry,\n  staleAt: number\n): void {\n  const rejectedEntry: RejectedSegmentCacheEntry = entry as any\n  rejectedEntry.status = EntryStatus.Rejected\n  rejectedEntry.staleAt = staleAt\n  if (entry.promise !== null) {\n    // NOTE: We don't currently propagate the reason the prefetch was canceled\n    // but we could by accepting a `reason` argument.\n    entry.promise.resolve(null)\n    entry.promise = null\n  }\n}\n\nasync function fetchRouteOnCacheMiss(\n  entry: PendingRouteCacheEntry,\n  task: PrefetchTask\n): Promise<void> {\n  // This function is allowed to use async/await because it contains the actual\n  // fetch that gets issued on a cache miss. Notice though that it does not\n  // return anything; it writes the result to the cache entry directly, then\n  // pings the scheduler to unblock the corresponding prefetch task.\n  const key = task.key\n  const href = key.href\n  const nextUrl = key.nextUrl\n  try {\n    const response = await fetchSegmentPrefetchResponse(href, '/_tree', nextUrl)\n    if (\n      !response ||\n      !response.ok ||\n      // 204 is a Cache miss. Though theoretically this shouldn't happen when\n      // PPR is enabled, because we always respond to route tree requests, even\n      // if it needs to be blockingly generated on demand.\n      response.status === 204 ||\n      !response.body\n    ) {\n      // Server responded with an error, or with a miss. We should still cache\n      // the response, but we can try again after 10 seconds.\n      rejectRouteCacheEntry(entry, Date.now() + 10 * 1000)\n      return\n    }\n    const prefetchStream = createPrefetchResponseStream(\n      response.body,\n      routeCacheLru,\n      entry\n    )\n    const serverData: RootTreePrefetch = await (createFromNextReadableStream(\n      prefetchStream\n    ) as Promise<RootTreePrefetch>)\n    if (serverData.buildId !== getAppBuildId()) {\n      // The server build does not match the client. Treat as a 404. During\n      // an actual navigation, the router will trigger an MPA navigation.\n      // TODO: Consider moving the build ID to a response header so we can check\n      // it before decoding the response, and so there's one way of checking\n      // across all response types.\n      rejectRouteCacheEntry(entry, Date.now() + 10 * 1000)\n      return\n    }\n\n    // This is a bit convoluted but it's taken from router-reducer and\n    // fetch-server-response\n    const canonicalUrl = response.redirected\n      ? createHrefFromUrl(urlToUrlWithoutFlightMarker(response.url))\n      : href\n\n    // Check whether the response varies based on the Next-Url header.\n    const varyHeader = response.headers.get('vary')\n    const couldBeIntercepted =\n      varyHeader !== null && varyHeader.includes(NEXT_URL)\n\n    fulfillRouteCacheEntry(\n      entry,\n      serverData.tree,\n      serverData.head,\n      serverData.isHeadPartial,\n      Date.now() + serverData.staleTime,\n      couldBeIntercepted,\n      canonicalUrl\n    )\n\n    if (!couldBeIntercepted && nextUrl !== null) {\n      // This route will never be intercepted. So we can use this entry for all\n      // requests to this route, regardless of the Next-Url header. This works\n      // because when reading the cache we always check for a valid\n      // non-intercepted entry first.\n      //\n      // Re-key the entry. Since we're in an async task, we must first confirm\n      // that the entry hasn't been concurrently modified by a different task.\n      const currentKeypath: Prefix<RouteCacheKeypath> = [href, nextUrl]\n      const expectedEntry = routeCacheMap.get(currentKeypath)\n      if (expectedEntry === entry) {\n        routeCacheMap.delete(currentKeypath)\n        const newKeypath: Prefix<RouteCacheKeypath> = [href]\n        routeCacheMap.set(newKeypath, entry)\n        // We don't need to update the LRU because the entry is already in it.\n        // But since we changed the keypath, we do need to update that, so we\n        // know how to remove it from the map if it gets evicted from the LRU.\n        entry.keypath = newKeypath\n      } else {\n        // Something else modified this entry already. Since the re-keying is\n        // just a performance optimization, we can safely skip it.\n      }\n    }\n  } catch (error) {\n    // Either the connection itself failed, or something bad happened while\n    // decoding the response.\n    rejectRouteCacheEntry(entry, Date.now() + 10 * 1000)\n  }\n}\n\nasync function fetchSegmentEntryOnCacheMiss(\n  route: FulfilledRouteCacheEntry,\n  segmentCacheEntry: PendingSegmentCacheEntry,\n  routeKey: RouteCacheKey,\n  segmentPath: string,\n  accessToken: string | null\n): Promise<void> {\n  // This function is allowed to use async/await because it contains the actual\n  // fetch that gets issued on a cache miss. Notice though that it does not\n  // return anything; it writes the result to the cache entry directly.\n  //\n  // Segment fetches are non-blocking so we don't need to ping the scheduler\n  // on completion.\n  const href = routeKey.href\n  try {\n    const response = await fetchSegmentPrefetchResponse(\n      href,\n      accessToken === '' ? segmentPath : `${segmentPath}.${accessToken}`,\n      routeKey.nextUrl\n    )\n    if (\n      !response ||\n      !response.ok ||\n      response.status === 204 || // Cache miss\n      !response.body\n    ) {\n      // Server responded with an error, or with a miss. We should still cache\n      // the response, but we can try again after 10 seconds.\n      rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000)\n      return\n    }\n    // Wrap the original stream in a new stream that never closes. That way the\n    // Flight client doesn't error if there's a hanging promise.\n    const prefetchStream = createPrefetchResponseStream(\n      response.body,\n      segmentCacheLru,\n      segmentCacheEntry\n    )\n    const serverData = await (createFromNextReadableStream(\n      prefetchStream\n    ) as Promise<SegmentPrefetch>)\n    if (serverData.buildId !== getAppBuildId()) {\n      // The server build does not match the client. Treat as a 404. During\n      // an actual navigation, the router will trigger an MPA navigation.\n      // TODO: Consider moving the build ID to a response header so we can check\n      // it before decoding the response, and so there's one way of checking\n      // across all response types.\n      rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000)\n      return\n    }\n    fulfillSegmentCacheEntry(\n      segmentCacheEntry,\n      serverData.rsc,\n      serverData.loading,\n      // TODO: The server does not currently provide per-segment stale time.\n      // So we use the stale time of the route.\n      route.staleAt,\n      serverData.isPartial\n    )\n  } catch (error) {\n    // Either the connection itself failed, or something bad happened while\n    // decoding the response.\n    rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000)\n  }\n}\n\nasync function fetchSegmentPrefetchResponse(\n  href: NormalizedHref,\n  segmentPath: string,\n  nextUrl: NormalizedNextUrl | null\n): Promise<Response | null> {\n  const headers: RequestHeaders = {\n    [RSC_HEADER]: '1',\n    [NEXT_ROUTER_PREFETCH_HEADER]: '1',\n    [NEXT_ROUTER_SEGMENT_PREFETCH_HEADER]: segmentPath,\n  }\n  if (nextUrl !== null) {\n    headers[NEXT_URL] = nextUrl\n  }\n  const fetchPriority = 'low'\n  const responsePromise = createFetch(new URL(href), headers, fetchPriority)\n  trackPrefetchRequestBandwidth(responsePromise)\n  const response = await responsePromise\n  const contentType = response.headers.get('content-type')\n  const isFlightResponse =\n    contentType && contentType.startsWith(RSC_CONTENT_TYPE_HEADER)\n  if (!response.ok || !isFlightResponse) {\n    return null\n  }\n  return response\n}\n\nfunction createPrefetchResponseStream<\n  T extends RouteCacheEntry | SegmentCacheEntry,\n>(\n  originalFlightStream: ReadableStream<Uint8Array>,\n  lru: LRU<T>,\n  lruEntry: T\n): ReadableStream<Uint8Array> {\n  // When PPR is enabled, prefetch streams may contain references that never\n  // resolve, because that's how we encode dynamic data access. In the decoded\n  // object returned by the Flight client, these are reified into hanging\n  // promises that suspend during render, which is effectively what we want.\n  // The UI resolves when it switches to the dynamic data stream\n  // (via useDeferredValue(dynamic, static)).\n  //\n  // However, the Flight implementation currently errors if the server closes\n  // the response before all the references are resolved. As a cheat to work\n  // around this, we wrap the original stream in a new stream that never closes,\n  // and therefore doesn't error.\n  //\n  // While processing the original stream, we also incrementally update the size\n  // of the cache entry in the LRU.\n  let totalByteLength = 0\n  const reader = originalFlightStream.getReader()\n  return new ReadableStream({\n    async pull(controller) {\n      while (true) {\n        const { done, value } = await reader.read()\n        if (!done) {\n          // Pass to the target stream and keep consuming the Flight response\n          // from the server.\n          controller.enqueue(value)\n\n          // Incrementally update the size of the cache entry in the LRU.\n          // NOTE: Since prefetch responses are delivered in a single chunk,\n          // it's not really necessary to do this streamingly, but I'm doing it\n          // anyway in case this changes in the future.\n          totalByteLength += value.byteLength\n          lru.updateSize(lruEntry, totalByteLength)\n\n          continue\n        }\n        // The server stream has closed. Exit, but intentionally do not close\n        // the target stream.\n        return\n      }\n    },\n  })\n}\n\nfunction createPromiseWithResolvers<T>(): PromiseWithResolvers<T> {\n  // Shim of Stage 4 Promise.withResolvers proposal\n  let resolve: (value: T | PromiseLike<T>) => void\n  let reject: (reason: any) => void\n  const promise = new Promise<T>((res, rej) => {\n    resolve = res\n    reject = rej\n  })\n  return { resolve: resolve!, reject: reject!, promise }\n}\n"],"names":["NEXT_ROUTER_PREFETCH_HEADER","NEXT_ROUTER_SEGMENT_PREFETCH_HEADER","NEXT_URL","RSC_CONTENT_TYPE_HEADER","RSC_HEADER","createFetch","createFromNextReadableStream","urlToUrlWithoutFlightMarker","trackPrefetchRequestBandwidth","pingPrefetchTask","spawnPrefetchSubtask","getAppBuildId","createHrefFromUrl","createTupleMap","createLRU","EntryStatus","routeCacheMap","maxRouteLruSize","routeCacheLru","onRouteLRUEviction","segmentCacheMap","Map","maxSegmentLruSize","segmentCacheLru","onSegmentLRUEviction","readExactRouteCacheEntry","now","href","nextUrl","keypath","existingEntry","get","staleAt","put","deleteRouteFromCache","readRouteCacheEntry","key","nonInterceptedEntry","couldBeIntercepted","readSegmentCacheEntry","path","undefined","deleteSegmentFromCache","waitForSegmentCacheEntry","pendingEntry","promiseWithResolvers","promise","createPromiseWithResolvers","requestRouteCacheEntryFromCache","task","exactEntry","canonicalUrl","status","blockedTasks","tree","head","isHeadPartial","next","prev","size","fetchRouteOnCacheMiss","set","requestSegmentEntryFromCache","route","accessToken","rsc","loading","isPartial","fetchSegmentEntryOnCacheMiss","entry","pingBlockedTasks","delete","cancelEntryListeners","resolve","fulfillRouteCacheEntry","fulfilledEntry","fulfillSegmentCacheEntry","segmentCacheEntry","rejectRouteCacheEntry","rejectedEntry","rejectSegmentCacheEntry","response","fetchSegmentPrefetchResponse","ok","body","Date","prefetchStream","createPrefetchResponseStream","serverData","buildId","redirected","url","varyHeader","headers","includes","staleTime","currentKeypath","expectedEntry","newKeypath","error","routeKey","segmentPath","fetchPriority","responsePromise","URL","contentType","isFlightResponse","startsWith","originalFlightStream","lru","lruEntry","totalByteLength","reader","getReader","ReadableStream","pull","controller","done","value","read","enqueue","byteLength","updateSize","reject","Promise","res","rej"],"mappings":"AAMA,SACEA,2BAA2B,EAC3BC,mCAAmC,EACnCC,QAAQ,EACRC,uBAAuB,EACvBC,UAAU,QACL,wBAAuB;AAC9B,SACEC,WAAW,EACXC,4BAA4B,EAC5BC,2BAA2B,QAEtB,0CAAyC;AAChD,SACEC,6BAA6B,EAC7BC,gBAAgB,EAEhBC,oBAAoB,QACf,cAAa;AACpB,SAASC,aAAa,QAAQ,qBAAoB;AAClD,SAASC,iBAAiB,QAAQ,yCAAwC;AAM1E,SAASC,cAAc,QAAoC,cAAa;AACxE,SAASC,SAAS,QAAkB,QAAO;AAqC3C,OAAO,IAAA,AAAWC,qCAAAA;;;;WAAAA;MAIjB;AA+ED,MAAMC,gBACJH;AAEF,8EAA8E;AAC9E,2DAA2D;AAC3D,+EAA+E;AAC/E,0EAA0E;AAC1E,4CAA4C;AAC5C,MAAMI,kBAAkB,KAAK,OAAO,KAAK,QAAQ;;AACjD,MAAMC,gBAAgBJ,UACpBG,iBACAE;AAGF,wEAAwE;AACxE,6BAA6B;AAC7B,MAAMC,kBAAkB,IAAIC;AAC5B,0EAA0E;AAC1E,4EAA4E;AAC5E,+EAA+E;AAC/E,8BAA8B;AAC9B,MAAMC,oBAAoB,KAAK,OAAO,KAAK,QAAQ;;AACnD,MAAMC,kBAAkBT,UACtBQ,mBACAE;AAGF,OAAO,SAASC,yBACdC,GAAW,EACXC,IAAoB,EACpBC,OAAiC;IAEjC,MAAMC,UACJD,YAAY,OAAO;QAACD;KAAK,GAAG;QAACA;QAAMC;KAAQ;IAC7C,MAAME,gBAAgBd,cAAce,GAAG,CAACF;IACxC,IAAIC,kBAAkB,MAAM;QAC1B,8BAA8B;QAC9B,IAAIA,cAAcE,OAAO,GAAGN,KAAK;YAC/B,4BAA4B;YAE5B,mEAAmE;YACnER,cAAce,GAAG,CAACH;YAElB,OAAOA;QACT,OAAO;YACL,wCAAwC;YACxCI,qBAAqBJ,eAAeD;QACtC;IACF;IACA,OAAO;AACT;AAEA,OAAO,SAASM,oBACdT,GAAW,EACXU,GAAkB;IAElB,wEAAwE;IACxE,2CAA2C;IAC3C,MAAMC,sBAAsBZ,yBAAyBC,KAAKU,IAAIT,IAAI,EAAE;IACpE,IAAIU,wBAAwB,QAAQ,CAACA,oBAAoBC,kBAAkB,EAAE;QAC3E,uEAAuE;QACvE,OAAOD;IACT;IACA,sEAAsE;IACtE,OAAOZ,yBAAyBC,KAAKU,IAAIT,IAAI,EAAES,IAAIR,OAAO;AAC5D;AAEA,OAAO,SAASW,sBACdb,GAAW,EACXc,IAAY;IAEZ,MAAMV,gBAAgBV,gBAAgBW,GAAG,CAACS;IAC1C,IAAIV,kBAAkBW,WAAW;QAC/B,8BAA8B;QAC9B,IAAIX,cAAcE,OAAO,GAAGN,KAAK;YAC/B,4BAA4B;YAE5B,mEAAmE;YACnEH,gBAAgBU,GAAG,CAACH;YAEpB,OAAOA;QACT,OAAO;YACL,wCAAwC;YACxCY,uBAAuBZ,eAAeU;QACxC;IACF;IACA,OAAO;AACT;AAEA,OAAO,SAASG,yBACdC,YAAsC;IAEtC,uEAAuE;IACvE,4EAA4E;IAC5E,IAAIC,uBAAuBD,aAAaE,OAAO;IAC/C,IAAID,yBAAyB,MAAM;QACjCA,uBAAuBD,aAAaE,OAAO,GACzCC;IACJ,OAAO;IACL,uCAAuC;IACzC;IACA,OAAOF,qBAAqBC,OAAO;AACrC;AAEA;;;;CAIC,GACD,OAAO,SAASE,gCACdtB,GAAW,EACXuB,IAAkB;IAElB,MAAMb,MAAMa,KAAKb,GAAG;IACpB,wEAAwE;IACxE,2CAA2C;IAC3C,MAAMC,sBAAsBZ,yBAAyBC,KAAKU,IAAIT,IAAI,EAAE;IACpE,IAAIU,wBAAwB,QAAQ,CAACA,oBAAoBC,kBAAkB,EAAE;QAC3E,uEAAuE;QACvE,OAAOD;IACT;IACA,sEAAsE;IACtE,MAAMa,aAAazB,yBAAyBC,KAAKU,IAAIT,IAAI,EAAES,IAAIR,OAAO;IACtE,IAAIsB,eAAe,MAAM;QACvB,OAAOA;IACT;IACA,2DAA2D;IAC3D,MAAMN,eAAuC;QAC3CO,cAAc;QACdC,MAAM;QACNC,cAAc;QACdC,MAAM;QACNC,MAAM;QACNC,eAAe;QACf,yEAAyE;QACzE,yCAAyC;QACzC,EAAE;QACF,4EAA4E;QAC5E,gDAAgD;QAChDxB,SAASN,MAAM,KAAK;QACpB,0EAA0E;QAC1E,0EAA0E;QAC1E,mBAAmB;QACnBY,oBAAoB;QAEpB,qBAAqB;QACrBT,SAAS;QACT4B,MAAM;QACNC,MAAM;QACNC,MAAM;IACR;IACAjD,qBAAqBkD,sBAAsBhB,cAAcK;IACzD,MAAMpB,UACJO,IAAIR,OAAO,KAAK,OAAO;QAACQ,IAAIT,IAAI;KAAC,GAAG;QAACS,IAAIT,IAAI;QAAES,IAAIR,OAAO;KAAC;IAC7DZ,cAAc6C,GAAG,CAAChC,SAASe;IAC3B,0EAA0E;IAC1E,mCAAmC;IACnCA,aAAaf,OAAO,GAAGA;IACvBX,cAAce,GAAG,CAACW;IAClB,OAAOA;AACT;AAEA;;;;CAIC,GACD,OAAO,SAASkB,6BACdpC,GAAW,EACXuB,IAAkB,EAClBc,KAA+B,EAC/BvB,IAAY,EACZwB,WAAmB;IAEnB,MAAMlC,gBAAgBS,sBAAsBb,KAAKc;IACjD,IAAIV,kBAAkB,MAAM;QAC1B,OAAOA;IACT;IACA,2DAA2D;IAC3D,MAAMc,eAAyC;QAC7CQ,MAAM;QACNa,KAAK;QACLC,SAAS;QACTlC,SAAS+B,MAAM/B,OAAO;QACtBmC,WAAW;QACXrB,SAAS;QAET,qBAAqB;QACrBV,KAAK;QACLqB,MAAM;QACNC,MAAM;QACNC,MAAM;IACR;IACAjD,qBACE0D,6BACEL,OACAnB,cACAK,KAAKb,GAAG,EACRI,MACAwB;IAGJ5C,gBAAgByC,GAAG,CAACrB,MAAMI;IAC1B,0EAA0E;IAC1E,mCAAmC;IACnCA,aAAaR,GAAG,GAAGI;IACnBjB,gBAAgBU,GAAG,CAACW;IACpB,OAAOA;AACT;AAEA,SAASV,qBACPmC,KAAsB,EACtBxC,OAAkC;IAElCyC,iBAAiBD;IACjBrD,cAAcuD,MAAM,CAAC1C;IACrBX,cAAcqD,MAAM,CAACF;AACvB;AAEA,SAAS3B,uBAAuB2B,KAAwB,EAAEjC,GAAW;IACnEoC,qBAAqBH;IACrBjD,gBAAgBmD,MAAM,CAACnC;IACvBb,gBAAgBgD,MAAM,CAACF;AACzB;AAEA,SAASlD,mBAAmBkD,KAAsB;IAChD,sDAAsD;IACtD,MAAMxC,UAAUwC,MAAMxC,OAAO;IAC7B,IAAIA,YAAY,MAAM;QACpBwC,MAAMxC,OAAO,GAAG;QAChByC,iBAAiBD;QACjBrD,cAAcuD,MAAM,CAAC1C;IACvB;AACF;AAEA,SAASL,qBAAqB6C,KAAwB;IACpD,sDAAsD;IACtD,MAAMjC,MAAMiC,MAAMjC,GAAG;IACrB,IAAIA,QAAQ,MAAM;QAChBiC,MAAMjC,GAAG,GAAG;QACZoC,qBAAqBH;QACrBjD,gBAAgBmD,MAAM,CAACnC;IACzB;AACF;AAEA,SAASoC,qBAAqBH,KAAwB;IACpD,IAAIA,MAAMjB,MAAM,UAA4BiB,MAAMvB,OAAO,KAAK,MAAM;QAClE,4EAA4E;QAC5E,4EAA4E;QAC5E,aAAa;QACb,0EAA0E;QAC1E,iDAAiD;QACjDuB,MAAMvB,OAAO,CAAC2B,OAAO,CAAC;QACtBJ,MAAMvB,OAAO,GAAG;IAClB;AACF;AAEA,SAASwB,iBAAiBD,KAEzB;IACC,MAAMhB,eAAegB,MAAMhB,YAAY;IACvC,IAAIA,iBAAiB,MAAM;QACzB,KAAK,MAAMJ,QAAQI,aAAc;YAC/B5C,iBAAiBwC;QACnB;QACAoB,MAAMhB,YAAY,GAAG;IACvB;AACF;AAEA,SAASqB,uBACPL,KAA6B,EAC7Bf,IAAkB,EAClBC,IAAqB,EACrBC,aAAsB,EACtBxB,OAAe,EACfM,kBAA2B,EAC3Ba,YAAoB;IAEpB,MAAMwB,iBAA2CN;IACjDM,eAAevB,MAAM;IACrBuB,eAAerB,IAAI,GAAGA;IACtBqB,eAAepB,IAAI,GAAGA;IACtBoB,eAAenB,aAAa,GAAGA;IAC/BmB,eAAe3C,OAAO,GAAGA;IACzB2C,eAAerC,kBAAkB,GAAGA;IACpCqC,eAAexB,YAAY,GAAGA;IAC9BmB,iBAAiBD;IACjB,OAAOM;AACT;AAEA,SAASC,yBACPC,iBAA2C,EAC3CZ,GAAoB,EACpBC,OAAuD,EACvDlC,OAAe,EACfmC,SAAkB;IAElB,MAAMQ,iBAA6CE;IACnDF,eAAevB,MAAM;IACrBuB,eAAeV,GAAG,GAAGA;IACrBU,eAAeT,OAAO,GAAGA;IACzBS,eAAe3C,OAAO,GAAGA;IACzB2C,eAAeR,SAAS,GAAGA;IAC3B,yDAAyD;IACzD,IAAIU,kBAAkB/B,OAAO,KAAK,MAAM;QACtC+B,kBAAkB/B,OAAO,CAAC2B,OAAO,CAACE;QAClC,2CAA2C;QAC3CA,eAAe7B,OAAO,GAAG;IAC3B;AACF;AAEA,SAASgC,sBACPT,KAA6B,EAC7BrC,OAAe;IAEf,MAAM+C,gBAAyCV;IAC/CU,cAAc3B,MAAM;IACpB2B,cAAc/C,OAAO,GAAGA;IACxBsC,iBAAiBD;AACnB;AAEA,SAASW,wBACPX,KAA+B,EAC/BrC,OAAe;IAEf,MAAM+C,gBAA2CV;IACjDU,cAAc3B,MAAM;IACpB2B,cAAc/C,OAAO,GAAGA;IACxB,IAAIqC,MAAMvB,OAAO,KAAK,MAAM;QAC1B,0EAA0E;QAC1E,iDAAiD;QACjDuB,MAAMvB,OAAO,CAAC2B,OAAO,CAAC;QACtBJ,MAAMvB,OAAO,GAAG;IAClB;AACF;AAEA,eAAec,sBACbS,KAA6B,EAC7BpB,IAAkB;IAElB,6EAA6E;IAC7E,yEAAyE;IACzE,0EAA0E;IAC1E,kEAAkE;IAClE,MAAMb,MAAMa,KAAKb,GAAG;IACpB,MAAMT,OAAOS,IAAIT,IAAI;IACrB,MAAMC,UAAUQ,IAAIR,OAAO;IAC3B,IAAI;QACF,MAAMqD,WAAW,MAAMC,6BAA6BvD,MAAM,UAAUC;QACpE,IACE,CAACqD,YACD,CAACA,SAASE,EAAE,IACZ,uEAAuE;QACvE,yEAAyE;QACzE,oDAAoD;QACpDF,SAAS7B,MAAM,KAAK,OACpB,CAAC6B,SAASG,IAAI,EACd;YACA,wEAAwE;YACxE,uDAAuD;YACvDN,sBAAsBT,OAAOgB,KAAK3D,GAAG,KAAK,KAAK;YAC/C;QACF;QACA,MAAM4D,iBAAiBC,6BACrBN,SAASG,IAAI,EACblE,eACAmD;QAEF,MAAMmB,aAA+B,MAAOlF,6BAC1CgF;QAEF,IAAIE,WAAWC,OAAO,KAAK9E,iBAAiB;YAC1C,qEAAqE;YACrE,mEAAmE;YACnE,0EAA0E;YAC1E,sEAAsE;YACtE,6BAA6B;YAC7BmE,sBAAsBT,OAAOgB,KAAK3D,GAAG,KAAK,KAAK;YAC/C;QACF;QAEA,kEAAkE;QAClE,wBAAwB;QACxB,MAAMyB,eAAe8B,SAASS,UAAU,GACpC9E,kBAAkBL,4BAA4B0E,SAASU,GAAG,KAC1DhE;QAEJ,kEAAkE;QAClE,MAAMiE,aAAaX,SAASY,OAAO,CAAC9D,GAAG,CAAC;QACxC,MAAMO,qBACJsD,eAAe,QAAQA,WAAWE,QAAQ,CAAC5F;QAE7CwE,uBACEL,OACAmB,WAAWlC,IAAI,EACfkC,WAAWjC,IAAI,EACfiC,WAAWhC,aAAa,EACxB6B,KAAK3D,GAAG,KAAK8D,WAAWO,SAAS,EACjCzD,oBACAa;QAGF,IAAI,CAACb,sBAAsBV,YAAY,MAAM;YAC3C,yEAAyE;YACzE,wEAAwE;YACxE,6DAA6D;YAC7D,+BAA+B;YAC/B,EAAE;YACF,wEAAwE;YACxE,wEAAwE;YACxE,MAAMoE,iBAA4C;gBAACrE;gBAAMC;aAAQ;YACjE,MAAMqE,gBAAgBjF,cAAce,GAAG,CAACiE;YACxC,IAAIC,kBAAkB5B,OAAO;gBAC3BrD,cAAcuD,MAAM,CAACyB;gBACrB,MAAME,aAAwC;oBAACvE;iBAAK;gBACpDX,cAAc6C,GAAG,CAACqC,YAAY7B;gBAC9B,sEAAsE;gBACtE,qEAAqE;gBACrE,sEAAsE;gBACtEA,MAAMxC,OAAO,GAAGqE;YAClB,OAAO;YACL,qEAAqE;YACrE,0DAA0D;YAC5D;QACF;IACF,EAAE,OAAOC,OAAO;QACd,uEAAuE;QACvE,yBAAyB;QACzBrB,sBAAsBT,OAAOgB,KAAK3D,GAAG,KAAK,KAAK;IACjD;AACF;AAEA,eAAe0C,6BACbL,KAA+B,EAC/Bc,iBAA2C,EAC3CuB,QAAuB,EACvBC,WAAmB,EACnBrC,WAA0B;IAE1B,6EAA6E;IAC7E,yEAAyE;IACzE,qEAAqE;IACrE,EAAE;IACF,0EAA0E;IAC1E,iBAAiB;IACjB,MAAMrC,OAAOyE,SAASzE,IAAI;IAC1B,IAAI;QACF,MAAMsD,WAAW,MAAMC,6BACrBvD,MACAqC,gBAAgB,KAAKqC,cAAc,AAAGA,cAAY,MAAGrC,aACrDoC,SAASxE,OAAO;QAElB,IACE,CAACqD,YACD,CAACA,SAASE,EAAE,IACZF,SAAS7B,MAAM,KAAK,OAAO,aAAa;QACxC,CAAC6B,SAASG,IAAI,EACd;YACA,wEAAwE;YACxE,uDAAuD;YACvDJ,wBAAwBH,mBAAmBQ,KAAK3D,GAAG,KAAK,KAAK;YAC7D;QACF;QACA,2EAA2E;QAC3E,4DAA4D;QAC5D,MAAM4D,iBAAiBC,6BACrBN,SAASG,IAAI,EACb7D,iBACAsD;QAEF,MAAMW,aAAa,MAAOlF,6BACxBgF;QAEF,IAAIE,WAAWC,OAAO,KAAK9E,iBAAiB;YAC1C,qEAAqE;YACrE,mEAAmE;YACnE,0EAA0E;YAC1E,sEAAsE;YACtE,6BAA6B;YAC7BqE,wBAAwBH,mBAAmBQ,KAAK3D,GAAG,KAAK,KAAK;YAC7D;QACF;QACAkD,yBACEC,mBACAW,WAAWvB,GAAG,EACduB,WAAWtB,OAAO,EAClB,sEAAsE;QACtE,yCAAyC;QACzCH,MAAM/B,OAAO,EACbwD,WAAWrB,SAAS;IAExB,EAAE,OAAOgC,OAAO;QACd,uEAAuE;QACvE,yBAAyB;QACzBnB,wBAAwBH,mBAAmBQ,KAAK3D,GAAG,KAAK,KAAK;IAC/D;AACF;AAEA,eAAewD,6BACbvD,IAAoB,EACpB0E,WAAmB,EACnBzE,OAAiC;IAEjC,MAAMiE,UAA0B;QAC9B,CAACzF,WAAW,EAAE;QACd,CAACJ,4BAA4B,EAAE;QAC/B,CAACC,oCAAoC,EAAEoG;IACzC;IACA,IAAIzE,YAAY,MAAM;QACpBiE,OAAO,CAAC3F,SAAS,GAAG0B;IACtB;IACA,MAAM0E,gBAAgB;IACtB,MAAMC,kBAAkBlG,YAAY,IAAImG,IAAI7E,OAAOkE,SAASS;IAC5D9F,8BAA8B+F;IAC9B,MAAMtB,WAAW,MAAMsB;IACvB,MAAME,cAAcxB,SAASY,OAAO,CAAC9D,GAAG,CAAC;IACzC,MAAM2E,mBACJD,eAAeA,YAAYE,UAAU,CAACxG;IACxC,IAAI,CAAC8E,SAASE,EAAE,IAAI,CAACuB,kBAAkB;QACrC,OAAO;IACT;IACA,OAAOzB;AACT;AAEA,SAASM,6BAGPqB,oBAAgD,EAChDC,GAAW,EACXC,QAAW;IAEX,0EAA0E;IAC1E,4EAA4E;IAC5E,uEAAuE;IACvE,0EAA0E;IAC1E,8DAA8D;IAC9D,2CAA2C;IAC3C,EAAE;IACF,2EAA2E;IAC3E,0EAA0E;IAC1E,8EAA8E;IAC9E,+BAA+B;IAC/B,EAAE;IACF,8EAA8E;IAC9E,iCAAiC;IACjC,IAAIC,kBAAkB;IACtB,MAAMC,SAASJ,qBAAqBK,SAAS;IAC7C,OAAO,IAAIC,eAAe;QACxB,MAAMC,MAAKC,UAAU;YACnB,MAAO,KAAM;gBACX,MAAM,EAAEC,IAAI,EAAEC,KAAK,EAAE,GAAG,MAAMN,OAAOO,IAAI;gBACzC,IAAI,CAACF,MAAM;oBACT,mEAAmE;oBACnE,mBAAmB;oBACnBD,WAAWI,OAAO,CAACF;oBAEnB,+DAA+D;oBAC/D,kEAAkE;oBAClE,qEAAqE;oBACrE,6CAA6C;oBAC7CP,mBAAmBO,MAAMG,UAAU;oBACnCZ,IAAIa,UAAU,CAACZ,UAAUC;oBAEzB;gBACF;gBACA,qEAAqE;gBACrE,qBAAqB;gBACrB;YACF;QACF;IACF;AACF;AAEA,SAAShE;IACP,iDAAiD;IACjD,IAAI0B;IACJ,IAAIkD;IACJ,MAAM7E,UAAU,IAAI8E,QAAW,CAACC,KAAKC;QACnCrD,UAAUoD;QACVF,SAASG;IACX;IACA,OAAO;QAAErD,SAASA;QAAUkD,QAAQA;QAAS7E;IAAQ;AACvD"}